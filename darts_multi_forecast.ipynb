{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install mamba\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFtZVuw-Apk6",
        "outputId": "7e1ab1b7-eda7-43c0-edce-77a833374ca3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting mamba\n",
            "  Downloading mamba-0.11.3.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clint (from mamba)\n",
            "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from mamba)\n",
            "  Downloading coverage-7.6.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting args (from clint->mamba)\n",
            "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading coverage-7.6.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mamba, clint, args\n",
            "  Building wheel for mamba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba: filename=mamba-0.11.3-py3-none-any.whl size=16290 sha256=7eea86862a5cae2f3495eb1291f267fe4b7b1ca3e36e0df6675254a6f7a6d2bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/17/87/0c6977b03e2d11fa43ca902080bb7e1d76334f33cfaca2cc34\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34459 sha256=d877706a7a10f5f859db1808755dcad2e9f40de7d1c3ea923988a93642a289fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/8d/f3/91dd49f9a8c6a57be7715f6d11347c49971dd292a53397ed79\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3319 sha256=0e4fbb547dd5bb864cd27c6f9170dd7b2ba9d2475a87d47d58c2e1920401e359\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/a2/87/2541eb895fd18fd20cc7dd18b14d3b61bd9084cf4322abd15e\n",
            "Successfully built mamba clint args\n",
            "Installing collected packages: args, coverage, clint, mamba\n",
            "Successfully installed args-0.1.0 clint-0.5.1 coverage-7.6.12 mamba-0.11.3\n",
            "usage: mamba [-h] [--version] [--slow SLOW] [--enable-coverage] [--coverage-file COVERAGE_FILE]\n",
            "             [--format FORMAT] [--no-color] [--tags TAGS]\n",
            "             [specs ...]\n",
            "mamba: error: unrecognized arguments: -c conda-forge -c pytorch -c nvidia autogluon pytorch=*=*cuda* -y\n",
            "usage: mamba [-h] [--version] [--slow SLOW] [--enable-coverage] [--coverage-file COVERAGE_FILE]\n",
            "             [--format FORMAT] [--no-color] [--tags TAGS]\n",
            "             [specs ...]\n",
            "mamba: error: unrecognized arguments: -c conda-forge ray-tune>=2.10.0,<2.32 ray-default>=2.10.0,<2.32 -y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mamba install 'pytorch=*=*cuda*'\n",
        "!mamba install  'ray-tune>=2.10.0,<2.32' 'ray-default>=2.10.0,<2.32'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V05ICM2CBWom",
        "outputId": "29a7a489-e445-4c80-8f80-99351e8bcd1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[32m\u001b[22m0 examples ran in 0.0000 seconds\u001b[39m\u001b[22m\n",
            "\n",
            "\n",
            "\u001b[32m\u001b[22m0 examples ran in 0.0000 seconds\u001b[39m\u001b[22m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m4SbtP3Bi6g",
        "outputId": "811e7e69-ffee-4b9f-9995-7c2b62a04911"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  1 01:22:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0             27W /   70W |     516MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXCFESeIAkhM",
        "outputId": "fcf4827c-c653-4780-9cfd-79cb102ddf73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CUDA available: Tesla T4\n",
            "Memory available: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import logging\n",
        "import os\n",
        "from typing import Dict, List, Optional, Union, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up logging\n",
        "log_dir = './logs'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(log_dir, 'darts_training_alpine_valley.log'),\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "# GPU setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    from torch.cuda.amp import GradScaler\n",
        "    scaler = GradScaler(enabled=True)\n",
        "    print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install darts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYgJ9pmMAqIW",
        "outputId": "6e4701c6-5495-4ca3-beb0-5454de46ca37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting darts\n",
            "  Downloading darts-0.33.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from darts) (0.67)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from darts) (3.10.0)\n",
            "Collecting nfoursid>=1.0.0 (from darts)\n",
            "  Downloading nfoursid-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from darts) (2.2.2)\n",
            "Collecting pmdarima>=1.8.0 (from darts)\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting pyod>=0.9.5 (from darts)\n",
            "  Downloading pyod-2.0.3.tar.gz (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.6/169.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from darts) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from darts) (1.13.1)\n",
            "Requirement already satisfied: shap>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.46.0)\n",
            "Collecting statsforecast>=1.4 (from darts)\n",
            "  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.14.4)\n",
            "Collecting tbats>=1.1.0 (from darts)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.11/dist-packages (from darts) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from darts) (4.12.2)\n",
            "Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2025.1.2)\n",
            "Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.1.4)\n",
            "Collecting pytorch-lightning>=1.5.0 (from darts)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.1 (from darts)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.5.1+cu124)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays>=0.11.1->darts) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (3.0.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (2.3.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (75.1.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from pyod>=0.9.5->darts) (0.61.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.1->darts) (3.5.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (3.1.1)\n",
            "Collecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts)\n",
            "  Downloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts)\n",
            "  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->darts) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.1->darts) (4.25.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->darts) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.11.13)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->darts) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.18.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (18.1.0)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Downloading darts-0.33.0-py3-none-any.whl (972 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m972.2/972.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
            "Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.3-py3-none-any.whl size=200466 sha256=ca8aafcdee4ad930a28b55e2ad58bf18e2c9a58586640bbb4355255b66c0abc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/60/5b/f74eccd2c9c892a2c298202ca510f10995f9940647fcc2d97f\n",
            "Successfully built pyod\n",
            "Installing collected packages: appdirs, tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, fs, coreforecast, nvidia-cusparse-cu12, nvidia-cudnn-cu12, utilsforecast, triad, pyod, nvidia-cusolver-cu12, nfoursid, pmdarima, adagio, torchmetrics, tbats, fugue, statsforecast, pytorch-lightning, darts\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed adagio-0.2.6 appdirs-1.4.4 coreforecast-0.0.15 darts-0.33.0 fs-2.4.16 fugue-0.9.1 lightning-utilities-0.12.0 nfoursid-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pmdarima-2.0.4 pyod-2.0.3 pytorch-lightning-2.5.0.post0 statsforecast-2.0.1 tbats-1.1.3 tensorboardX-2.6.2.2 torchmetrics-1.6.1 triad-0.9.8 utilsforecast-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "CrxuS9cJAkhN"
      },
      "outputs": [],
      "source": [
        "# Import Darts components\n",
        "from darts.models import NBEATSModel, BlockRNNModel, TCNModel, TFTModel\n",
        "from darts.metrics import mape, mae, mase\n",
        "from darts import TimeSeries\n",
        "from darts.utils.likelihood_models import GaussianLikelihood\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnmNv35qAkhO",
        "outputId": "677217f2-23c4-41f3-b1aa-142e4e7fd0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_path: /content/maurienne_valley_20_years_daily_data.csv\n",
            "date_column: Date\n",
            "target_columns: ['Mean Temperature (°C)', 'Min Temperature (°C)', 'Max Temperature (°C)']\n",
            "target_year: 2050\n",
            "valley_ids: ['maurienne']\n",
            "frequency: D\n",
            "model_type: TFTModel\n",
            "input_chunk_length: 365\n",
            "output_chunk_length: 30\n",
            "n_epochs: 10\n",
            "use_covariates: True\n",
            "validation_length: 730\n",
            "random_state: 42\n"
          ]
        }
      ],
      "source": [
        "# Configuration dictionary - adjust as needed\n",
        "CONFIG = {\n",
        "    \"data_path\": \"/content/maurienne_valley_20_years_daily_data.csv\",  # Update with your path\n",
        "    \"date_column\": \"Date\",\n",
        "    \"target_columns\": [\"Mean Temperature (°C)\", \"Min Temperature (°C)\", \"Max Temperature (°C)\"],\n",
        "    \"target_year\": 2050,\n",
        "    \"valley_ids\": [\"maurienne\"],  # Add \"susa\" when using data from both valleys\n",
        "    \"frequency\": \"D\",  # \"D\" for daily, \"M\" for monthly\n",
        "    \"model_type\": \"TFTModel\",  # Options: \"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"\n",
        "    \"input_chunk_length\": 365,  # Lookback window (1 year of daily data)\n",
        "    \"output_chunk_length\": 30,  # Output window (1 month of daily data)\n",
        "    \"n_epochs\": 10,\n",
        "    \"use_covariates\": True,\n",
        "    \"validation_length\": 365 * 2,  # 2 years of daily data\n",
        "    \"random_state\": 42,\n",
        "}\n",
        "\n",
        "# Display configuration for review\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "SVrMSDyaAkhO"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster:\n",
        "    def __init__(self, config: Dict) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the WeatherForecaster with the given configuration.\n",
        "\n",
        "        Args:\n",
        "            config (Dict): Configuration dictionary containing parameters for data loading,\n",
        "                           model training, and forecasting.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.scalers = {}\n",
        "        self.full_history = None\n",
        "        self.covariates = None\n",
        "\n",
        "    def _load_data(self) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Load and preprocess time series data.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary mapping valley IDs to TimeSeries objects.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(self.config[\"data_path\"])\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[self.config[\"date_column\"]])\n",
        "\n",
        "        series_dict = {}\n",
        "        for valley_id in self.config[\"valley_ids\"]:\n",
        "            # Filter data for this valley if needed\n",
        "            valley_df = df[df[\"item_id\"] == valley_id] if \"item_id\" in df.columns else df\n",
        "\n",
        "            # Select target columns\n",
        "            target_cols = self.config[\"target_columns\"]\n",
        "            valley_df = valley_df[[\"timestamp\"] + target_cols]\n",
        "\n",
        "            # Convert to Darts TimeSeries\n",
        "            ts = TimeSeries.from_dataframe(\n",
        "                valley_df,\n",
        "                time_col=\"timestamp\",\n",
        "                value_cols=target_cols\n",
        "            )\n",
        "            series_dict[valley_id] = ts\n",
        "\n",
        "        return series_dict\n",
        "\n",
        "    def _generate_covariates(self, series_dict: Dict[str, TimeSeries]) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Generate covariates for forecasting such as year, month, and day of year.\n",
        "\n",
        "        Args:\n",
        "            series_dict (Dict[str, TimeSeries]): Dictionary of time series data.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary of covariate time series.\n",
        "        \"\"\"\n",
        "        covariates_dict = {}\n",
        "        for valley_id, ts in series_dict.items():\n",
        "            # Create year and month covariates\n",
        "            year_series = datetime_attribute_timeseries(ts, attribute=\"year\")\n",
        "            month_series = datetime_attribute_timeseries(ts, attribute=\"month\")\n",
        "            day_of_year_series = datetime_attribute_timeseries(ts, attribute=\"dayofyear\")\n",
        "\n",
        "            # Normalize covariates\n",
        "            scaler = Scaler()\n",
        "            year_series = scaler.fit_transform(year_series)\n",
        "            month_series = scaler.fit_transform(month_series)\n",
        "            day_of_year_series = scaler.fit_transform(day_of_year_series)\n",
        "\n",
        "            # Stack covariates\n",
        "            covariates = year_series.stack(month_series).stack(day_of_year_series)\n",
        "            covariates_dict[valley_id] = covariates\n",
        "\n",
        "        return covariates_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "Nd3xORKzAkhO"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _preprocess_data(self, series_dict: Dict[str, TimeSeries]) -> Tuple[Dict[str, TimeSeries], Dict[str, TimeSeries]]:\n",
        "      \"\"\"Preprocess time series data, ensuring adequate history for covariates.\"\"\"\n",
        "      train_dict = {}\n",
        "      val_dict = {}\n",
        "\n",
        "      for valley_id, ts in series_dict.items():\n",
        "          # Split into training and validation\n",
        "          val_length = self.config.get(\"validation_length\", 24)  # 2 years of monthly data by default\n",
        "\n",
        "          # Calculate minimum data needed for training\n",
        "          input_chunk_length = self.config.get(\"input_chunk_length\", 24)\n",
        "\n",
        "          # Ensure we have at least input_chunk_length history before starting training\n",
        "          if len(ts) < val_length + input_chunk_length:\n",
        "              raise ValueError(f\"TimeSeries for {valley_id} is too short. Need at least {val_length + input_chunk_length} points.\")\n",
        "\n",
        "          # For TFT models, we start training after input_chunk_length to ensure past covariates are available\n",
        "          if self.config.get(\"model_type\") == \"TFTModel\":\n",
        "              train_ts, val_ts = ts[:-val_length], ts[-val_length:]\n",
        "          else:\n",
        "              train_ts, val_ts = ts[:-val_length], ts[-val_length:]\n",
        "\n",
        "          # Scale the data\n",
        "          scaler = Scaler()\n",
        "          train_ts_scaled = scaler.fit_transform(train_ts)\n",
        "          val_ts_scaled = scaler.transform(val_ts)\n",
        "\n",
        "          # Store the scaler for later use\n",
        "          self.scalers[valley_id] = scaler\n",
        "\n",
        "          train_dict[valley_id] = train_ts_scaled\n",
        "          val_dict[valley_id] = val_ts_scaled\n",
        "\n",
        "      return train_dict, val_dict\n",
        "\n",
        "\n",
        "    def _create_model(self) -> Union[NBEATSModel, BlockRNNModel, TCNModel, TFTModel]:\n",
        "      \"\"\"Create and return a forecasting model based on configuration.\"\"\"\n",
        "      model_type = self.config.get(\"model_type\", \"TFTModel\")\n",
        "      input_chunk_length = self.config.get(\"input_chunk_length\", 24)\n",
        "      output_chunk_length = self.config.get(\"output_chunk_length\", 12)\n",
        "      n_epochs = self.config.get(\"n_epochs\", 100)\n",
        "\n",
        "      # Common parameters for all models\n",
        "      common_params = {\n",
        "          \"input_chunk_length\": input_chunk_length,\n",
        "          \"output_chunk_length\": output_chunk_length,\n",
        "          \"n_epochs\": n_epochs,\n",
        "          \"random_state\": self.config.get(\"random_state\", 42),\n",
        "          \"likelihood\": GaussianLikelihood(),  # For probabilistic forecasts\n",
        "          \"force_reset\": True,\n",
        "          \"pl_trainer_kwargs\": {\n",
        "              \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "              \"devices\": 1,\n",
        "              \"log_every_n_steps\": 10,\n",
        "          }\n",
        "      }\n",
        "\n",
        "      # TFT-specific parameters with comprehensive encoders\n",
        "      if model_type == \"TFTModel\":\n",
        "          # Create encoders for both past and future\n",
        "          encoders = {\n",
        "              \"cyclic\": {\n",
        "                  \"past\": [\"month\", \"dayofyear\", \"weekday\"],  # Add past cyclic features\n",
        "                  \"future\": [\"month\", \"dayofyear\", \"weekday\"]  # Add future cyclic features\n",
        "              },\n",
        "              \"datetime_attribute\": {\n",
        "                  \"past\": [\"year\"],  # Add past datetime attributes\n",
        "                  \"future\": [\"year\"]  # Add future datetime attributes\n",
        "              },\n",
        "              \"position\": {\n",
        "                  \"past\": [\"relative\"],  # Add past position encoding\n",
        "                  \"future\": [\"relative\"]  # Add future position encoding\n",
        "              },\n",
        "              \"transformer\": Scaler()  # Ensure encodings are properly scaled\n",
        "          }\n",
        "\n",
        "          return TFTModel(\n",
        "              hidden_size=self.config.get(\"hidden_size\", 64),\n",
        "              lstm_layers=self.config.get(\"lstm_layers\", 1),\n",
        "              num_attention_heads=self.config.get(\"num_attention_heads\", 4),\n",
        "              dropout=self.config.get(\"dropout\", 0.1),\n",
        "              add_relative_index=True,  # Belt and suspenders approach\n",
        "              add_encoders=encoders,\n",
        "              **common_params\n",
        "          )\n",
        "      elif model_type == \"NBEATSModel\":\n",
        "          return NBEATSModel(**common_params)\n",
        "      elif model_type == \"BlockRNNModel\":\n",
        "          return BlockRNNModel(\n",
        "              model=self.config.get(\"rnn_type\", \"LSTM\"),\n",
        "              **common_params\n",
        "          )\n",
        "      elif model_type == \"TCNModel\":\n",
        "          return TCNModel(**common_params)\n",
        "      else:\n",
        "          raise ValueError(f\"Unsupported model type: {model_type}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ZMyDQeWYAkhO"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _train_model(self, train_dict: Dict[str, TimeSeries], val_dict: Dict[str, TimeSeries]) -> None:\n",
        "      \"\"\"Train the model with properly extended covariates.\"\"\"\n",
        "      # Create model\n",
        "      self.model = self._create_model()\n",
        "\n",
        "      # Convert dictionaries to lists for model.fit()\n",
        "      train_series = list(train_dict.values())\n",
        "      val_series = list(val_dict.values())\n",
        "\n",
        "      if isinstance(self.model, TFTModel):\n",
        "          # For TFT models, rely on the automatic encoders\n",
        "          # When using add_encoders, you don't need to explicitly provide covariates\n",
        "          self.model.fit(\n",
        "              series=train_series,\n",
        "              val_series=val_series,\n",
        "              verbose=True\n",
        "          )\n",
        "      elif self.config.get(\"use_covariates\", True):\n",
        "          # For other models that may need explicit covariates\n",
        "          self.covariates = self._generate_covariates({**train_dict, **val_dict})\n",
        "          covariates_list = list(self.covariates.values())\n",
        "\n",
        "          # Train with covariates\n",
        "          self.model.fit(\n",
        "              series=train_series,\n",
        "              past_covariates=covariates_list,\n",
        "              val_series=val_series,\n",
        "              val_past_covariates=covariates_list,\n",
        "              verbose=True\n",
        "          )\n",
        "      else:\n",
        "          # Basic model without covariates\n",
        "          self.model.fit(\n",
        "              series=train_series,\n",
        "              val_series=val_series,\n",
        "              verbose=True\n",
        "          )\n",
        "      # Log validation metrics after training\n",
        "      for valley_id, val_ts in val_dict.items():\n",
        "        # Make predictions on validation data\n",
        "        if self.config.get(\"use_covariates\", True) and self.covariates:\n",
        "            pred = self.model.predict(\n",
        "                n=len(val_ts),\n",
        "                series=train_dict[valley_id],\n",
        "                past_covariates=self.covariates[valley_id]\n",
        "            )\n",
        "        else:\n",
        "            pred = self.model.predict(\n",
        "                n=len(val_ts),\n",
        "                series=train_dict[valley_id]\n",
        "            )\n",
        "\n",
        "        # Inverse transform predictions and actual values\n",
        "        pred = self.scalers[valley_id].inverse_transform(pred)\n",
        "        actual = self.scalers[valley_id].inverse_transform(val_ts)\n",
        "\n",
        "        # Calculate and log metrics for each component/feature\n",
        "        for i, feature in enumerate(val_ts.components):\n",
        "            pred_univariate = pred.univariate_component(i)\n",
        "            actual_univariate = actual.univariate_component(i)\n",
        "\n",
        "            # Calculate metrics\n",
        "            mape_value = mape(actual_univariate, pred_univariate)\n",
        "            mae_value = mae(actual_univariate, pred_univariate)\n",
        "            mase_value = mase(actual_univariate, pred_univariate)\n",
        "\n",
        "            # Log metrics to wandb\n",
        "            wandb.log({\n",
        "                f\"{valley_id}_{feature}_mape\": mape_value,\n",
        "                f\"{valley_id}_{feature}_mae\": mae_value,\n",
        "                f\"{valley_id}_{feature}_mase\": mase_value\n",
        "            })\n",
        "\n",
        "      logging.info(f\"Model training completed: {self.model}\")\n",
        "\n",
        "\n",
        "    def _forecast(self, train_dict: Dict[str, TimeSeries], horizon: int) -> Dict[str, TimeSeries]:\n",
        "      \"\"\"Generate forecasts with proper handling of covariates.\"\"\"\n",
        "      forecasts = {}\n",
        "\n",
        "      for valley_id, ts in train_dict.items():\n",
        "          if isinstance(self.model, TFTModel):\n",
        "              # For TFT models using automatic encoders\n",
        "              forecast = self.model.predict(\n",
        "                  n=horizon,\n",
        "                  series=ts,\n",
        "                  num_samples=100  # For probabilistic forecasts\n",
        "              )\n",
        "          elif self.config.get(\"use_covariates\", True) and self.covariates:\n",
        "              # For other models with explicit covariates\n",
        "              forecast = self.model.predict(\n",
        "                  n=horizon,\n",
        "                  series=ts,\n",
        "                  past_covariates=self.covariates[valley_id],\n",
        "                  num_samples=100\n",
        "              )\n",
        "          else:\n",
        "              # Basic prediction without covariates\n",
        "              forecast = self.model.predict(\n",
        "                  n=horizon,\n",
        "                  series=ts,\n",
        "                  num_samples=100\n",
        "              )\n",
        "\n",
        "          # Inverse transform the forecast\n",
        "          forecast = self.scalers[valley_id].inverse_transform(forecast)\n",
        "          forecasts[valley_id] = forecast\n",
        "\n",
        "      return forecasts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "Vkivh1jQTEAP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "u0E35YA8AkhP"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _plot_forecasts(self,\n",
        "                        full_series: Dict[str, TimeSeries],\n",
        "                        forecasts: Dict[str, TimeSeries],\n",
        "                        val_series: Optional[Dict[str, TimeSeries]] = None) -> None:\n",
        "        \"\"\"\n",
        "        Plot forecasts with confidence intervals for each feature.\n",
        "\n",
        "        Args:\n",
        "            full_series (Dict[str, TimeSeries]): Dictionary of full historical time series.\n",
        "            forecasts (Dict[str, TimeSeries]): Dictionary of forecast time series.\n",
        "            val_series (Optional[Dict[str, TimeSeries]]): Dictionary of validation time series.\n",
        "        \"\"\"\n",
        "        feature_colors = {\n",
        "            \"Mean Temperature (°C)\": \"red\",\n",
        "            \"Min Temperature (°C)\": \"blue\",\n",
        "            \"Max Temperature (°C)\": \"green\",\n",
        "            # Add more features as needed\n",
        "        }\n",
        "\n",
        "        for valley_id in full_series.keys():\n",
        "            # Get feature names for this valley\n",
        "            feature_names = full_series[valley_id].components\n",
        "\n",
        "            # Plot each feature separately\n",
        "            for i, feature in enumerate(feature_names):\n",
        "                plt.figure(figsize=(15, 8))\n",
        "\n",
        "                # Plot historical data\n",
        "                hist_series = full_series[valley_id].univariate_component(i)\n",
        "                hist_series.plot(label=f\"{valley_id} - {feature} (Actual)\", color=feature_colors.get(feature, \"blue\"))\n",
        "\n",
        "                # Plot validation data if provided\n",
        "                if val_series and valley_id in val_series:\n",
        "                    val_data = val_series[valley_id].univariate_component(i)\n",
        "                    val_data.plot(label=f\"{valley_id} - {feature} (Validation)\", color=\"purple\", linestyle=\"--\")\n",
        "\n",
        "                # Plot forecast with confidence intervals\n",
        "                forecast = forecasts[valley_id].univariate_component(i)\n",
        "                forecast.plot(label=f\"{valley_id} - {feature} (Forecast)\", color=\"orange\")\n",
        "\n",
        "                # Plot confidence intervals if this is a probabilistic forecast\n",
        "                if forecast.n_samples > 1:\n",
        "                    p10, p90 = forecast.quantiles_timeseries(0.1, 0.9)\n",
        "                    plt.fill_between(\n",
        "                        forecast.time_index,\n",
        "                        p10.values().flatten(),\n",
        "                        p90.values().flatten(),\n",
        "                        alpha=0.2,\n",
        "                        color=\"orange\",\n",
        "                        label=\"80% Confidence Interval\"\n",
        "                    )\n",
        "\n",
        "                plt.title(f\"{feature} Forecast for {valley_id} Valley until {self.config['target_year']}\")\n",
        "                plt.xlabel(\"Year\")\n",
        "                plt.ylabel(feature)\n",
        "                plt.legend()\n",
        "                plt.grid(True)\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # In Colab, display the plot\n",
        "                plt.show()\n",
        "\n",
        "                # Save the plot to file\n",
        "                plt.savefig(f\"{valley_id}_{feature.replace(' ', '_')}_forecast.png\")\n",
        "                plt.close()\n",
        "\n",
        "                logging.info(f\"Plot saved for {valley_id} - {feature}\")\n",
        "\n",
        "    def run_pipeline(self) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Main execution flow for the forecasting pipeline.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary of forecast time series.\n",
        "        \"\"\"\n",
        "        # Load data\n",
        "        series_dict = self._load_data()\n",
        "        self.full_history = series_dict\n",
        "\n",
        "        # Preprocess data\n",
        "        train_dict, val_dict = self._preprocess_data(series_dict)\n",
        "\n",
        "        # Train model\n",
        "        self._train_model(train_dict, val_dict)\n",
        "\n",
        "        # Calculate forecast horizon\n",
        "        sample_ts = list(series_dict.values())[0]\n",
        "        forecast_end_year = self.config[\"target_year\"]\n",
        "        current_end_year = sample_ts.time_index[-1].year\n",
        "        years_to_forecast = forecast_end_year - current_end_year\n",
        "\n",
        "        # Convert years to number of time steps based on data frequency\n",
        "        steps_per_year = 12  # Assuming monthly data\n",
        "        if self.config.get(\"frequency\") == \"D\":\n",
        "            steps_per_year = 365\n",
        "        horizon = years_to_forecast * steps_per_year\n",
        "\n",
        "        print(f\"Forecasting {years_to_forecast} years ahead ({horizon} time steps)\")\n",
        "\n",
        "        # Generate forecasts\n",
        "        forecasts = self._forecast(train_dict, horizon)\n",
        "\n",
        "        # Plot results\n",
        "        self._plot_forecasts(self.full_history, forecasts, val_dict)\n",
        "\n",
        "        return forecasts\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5Qlg2eiPfPT",
        "outputId": "30623ceb-8157-42ca-bcc7-63b0078baaf7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWirNpYJQQqO",
        "outputId": "39215253-a979-42d5-e2f8-33b32cb62ef3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_d1QrI5Qq3U",
        "outputId": "2e766201-1eaf-47dd-f97e-6b6d58145061"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Alpine valley Hackathon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "m1fFC-GLRE7A",
        "outputId": "2dfbe30b-8dd5-4230-978d-0514d38862dc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250301_011403-8x48m0i6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon/runs/8x48m0i6' target=\"_blank\">generous-jazz-1</a></strong> to <a href='https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon' target=\"_blank\">https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon/runs/8x48m0i6' target=\"_blank\">https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon/runs/8x48m0i6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cantiuscloud2-self/Alpine%20valley%20Hackathon/runs/8x48m0i6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7dd515669d10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638,
          "referenced_widgets": [
            "3d9f3b1540e04a9c8dc369cf7ea96853",
            "ac51f535b479406a9e74620e2e885c4d",
            "928c638435d04547a8afe52498b7ec0d",
            "858659aedf6e45e780c141d6903b25e4",
            "4fb54cf5fa6c4b75965d9fbd7b449ece",
            "9327df0ece3f423da07db9584419a6b7",
            "a97fefff4147405e8e2a4757e4faecf6",
            "67d27d5b59524e6a9ff65564e58f5cfb",
            "87fe5e858b4f4b49a05810867213af01",
            "c995b4d87a3c40f2a67aac8ab4905fcc",
            "ab75b3bfe1644297962497b113a079c5",
            "84b7d7d61ef9440b9073e2670afa5ad1",
            "af39083bac504ec2bd56e3d364152a36",
            "a56e24bbf12e48e1995e571caef22075",
            "9d30cab9a73f4bf69e70938ed5f9fe72",
            "11421187daed46138be255091ae58e6d",
            "30b51e01688c4176a2928a8f0d7f5e5a",
            "c635c7ffa958460e9afbda5312fa9486",
            "1aa558b45f1c48c9a354b8a8edb34a7e",
            "29c75d710f034455a0a21498a99843bf",
            "2bbe7820e3344d04b3974132f4190719",
            "e72110fff52942f6bf5590673f12fc95"
          ]
        },
        "id": "POqfGFncAkhP",
        "outputId": "110c0deb-f872-463f-88f9-89968a57b3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "   | Name                              | Type                             | Params | Mode \n",
            "------------------------------------------------------------------------------------------------\n",
            "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
            "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
            "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
            "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
            "4  | encoder_vsn                       | _VariableSelectionNetwork        | 38.5 K | train\n",
            "5  | decoder_vsn                       | _VariableSelectionNetwork        | 16.2 K | train\n",
            "6  | static_context_grn                | _GatedResidualNetwork            | 16.8 K | train\n",
            "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 16.8 K | train\n",
            "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 16.8 K | train\n",
            "9  | static_context_enrichment         | _GatedResidualNetwork            | 16.8 K | train\n",
            "10 | lstm_encoder                      | LSTM                             | 33.3 K | train\n",
            "11 | lstm_decoder                      | LSTM                             | 33.3 K | train\n",
            "12 | post_lstm_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
            "13 | static_enrichment_grn             | _GatedResidualNetwork            | 20.9 K | train\n",
            "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 10.4 K | train\n",
            "15 | post_attn_gan                     | _GateAddNorm                     | 8.4 K  | train\n",
            "16 | feed_forward_block                | _GatedResidualNetwork            | 16.8 K | train\n",
            "17 | pre_output_gan                    | _GateAddNorm                     | 8.4 K  | train\n",
            "18 | output_layer                      | Linear                           | 390    | train\n",
            "------------------------------------------------------------------------------------------------\n",
            "261 K     Trainable params\n",
            "0         Non-trainable params\n",
            "261 K     Total params\n",
            "1.048     Total estimated model params size (MB)\n",
            "569       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d9f3b1540e04a9c8dc369cf7ea96853"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b7d7d61ef9440b9073e2670afa5ad1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create and run the forecaster\n",
        "forecaster = WeatherForecaster(CONFIG)\n",
        "results = forecaster.run_pipeline()\n",
        "print(f\"Forecasting complete. Results saved as PNG files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "53Rs3-zIAkhP"
      },
      "outputs": [],
      "source": [
        "# Optional: Compare different models\n",
        "def compare_models(config, target_columns=None):\n",
        "    \"\"\"Compare performance of different models on the dataset.\"\"\"\n",
        "    if target_columns is None:\n",
        "        target_columns = config[\"target_columns\"][:1]  # Just use first target for comparison\n",
        "\n",
        "    model_types = [\"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"]\n",
        "    results = {}\n",
        "\n",
        "    for model_type in model_types:\n",
        "        print(f\"\\nTraining {model_type}...\")\n",
        "\n",
        "        # Update config with current model\n",
        "        test_config = config.copy()\n",
        "        test_config[\"model_type\"] = model_type\n",
        "        test_config[\"target_columns\"] = target_columns\n",
        "        test_config[\"n_epochs\"] = 20  # Reduced for comparison\n",
        "\n",
        "        try:\n",
        "            forecaster = WeatherForecaster(test_config)\n",
        "            # Load data\n",
        "            series_dict = forecaster._load_data()\n",
        "            # Preprocess data\n",
        "            train_dict, val_dict = forecaster._preprocess_data(series_dict)\n",
        "            # Train model\n",
        "            forecaster._train_model(train_dict, val_dict)\n",
        "\n",
        "            # Calculate validation metrics\n",
        "            val_metrics = {}\n",
        "            for valley_id in val_dict.keys():\n",
        "                val_true = forecaster.scalers[valley_id].inverse_transform(val_dict[valley_id])\n",
        "\n",
        "                # Generate predictions for validation period\n",
        "                val_pred = forecaster.model.predict(\n",
        "                    n=len(val_true),\n",
        "                    series=train_dict[valley_id],\n",
        "                    past_covariates=forecaster.covariates[valley_id] if forecaster.covariates else None\n",
        "                )\n",
        "                val_pred = forecaster.scalers[valley_id].inverse_transform(val_pred)\n",
        "\n",
        "                # Calculate metrics\n",
        "                mae_val = mae(val_true, val_pred)\n",
        "                mape_val = mape(val_true, val_pred)\n",
        "                val_metrics[valley_id] = {\"MAE\": mae_val, \"MAPE\": mape_val}\n",
        "\n",
        "            results[model_type] = val_metrics\n",
        "            print(f\"{model_type} validation metrics: {val_metrics}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {model_type}: {str(e)}\")\n",
        "            results[model_type] = {\"error\": str(e)}\n",
        "\n",
        "    # Display comparison table\n",
        "    comparison_df = pd.DataFrame({\n",
        "        model: {f\"{valley_id}_MAE\": metrics.get(valley_id, {}).get(\"MAE\", None)\n",
        "                for valley_id in config[\"valley_ids\"]}\n",
        "        for model, metrics in results.items()\n",
        "    })\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "# Uncomment to run model comparison\n",
        "# model_comparison = compare_models(CONFIG)\n",
        "# model_comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "LihdW4g4AkhP"
      },
      "outputs": [],
      "source": [
        "def multistation_approach_example():\n",
        "    \"\"\"\n",
        "    Example of different approaches to handle multiple weather stations and valleys.\n",
        "    Showing code structure without actual implementation.\n",
        "    \"\"\"\n",
        "    print(\"Three main approaches for handling multiple valleys/stations:\")\n",
        "\n",
        "    # Approach 1: Item ID approach (like in the main code)\n",
        "    print(\"\\n1. Item ID Approach:\")\n",
        "    print(\"- Each valley/station is treated as a separate time series\")\n",
        "    print(\"- Advantage: Simple, allows different scaling per station\")\n",
        "    print(\"- Implementation: Already shown in main code\")\n",
        "\n",
        "    # Approach 2: Multivariate approach\n",
        "    print(\"\\n2. Multivariate Approach:\")\n",
        "    print(\"- All features from all stations in one multivariate time series\")\n",
        "    print(\"- Advantage: Model learns correlations between stations\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    # Example implementation (pseudocode):\n",
        "    def load_multivariate_data():\n",
        "        # Load data from all stations\n",
        "        all_stations_df = []\n",
        "        for station in stations:\n",
        "            df = pd.read_csv(f\"{station}_data.csv\")\n",
        "            # Rename columns to include station\n",
        "            for col in feature_columns:\n",
        "                df.rename(columns={col: f\"{col}_{station}\"}, inplace=True)\n",
        "            all_stations_df.append(df)\n",
        "\n",
        "        # Merge on timestamp\n",
        "        merged_df = pd.merge(all_stations_df, on=\"timestamp\")\n",
        "\n",
        "        # Convert to Darts TimeSeries\n",
        "        ts = TimeSeries.from_dataframe(\n",
        "            merged_df,\n",
        "            time_col=\"timestamp\",\n",
        "            value_cols=[f\"{col}_{station}\" for col in feature_columns for station in stations]\n",
        "        )\n",
        "        return ts\n",
        "    \"\"\")\n",
        "\n",
        "    # Approach 3: One-hot encoding approach\n",
        "    print(\"\\n3. One-hot Encoding Approach:\")\n",
        "    print(\"- Add station/valley identifiers as one-hot encoded features\")\n",
        "    print(\"- Advantage: Allows model to learn location-specific patterns\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    # Example implementation (pseudocode):\n",
        "    def generate_station_covariates(ts, station_id):\n",
        "        # Create one-hot encoding for stations\n",
        "        station_ids = [\"station1\", \"station2\", \"station3\", \"station4\"]\n",
        "        one_hot = [1 if station_id == sid else 0 for sid in station_ids]\n",
        "\n",
        "        # Create covariates TimeSeries with same time index\n",
        "        covariates_data = np.tile(one_hot, (len(ts), 1))\n",
        "        covariates = TimeSeries.from_values(covariates_data, index=ts.time_index)\n",
        "\n",
        "        return covariates\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nRecommendation: Use multivariate approach for stations within the same valley,\")\n",
        "    print(\"and item_id approach for different valleys.\")\n",
        "\n",
        "# multistation_approach_example()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d9f3b1540e04a9c8dc369cf7ea96853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac51f535b479406a9e74620e2e885c4d",
              "IPY_MODEL_928c638435d04547a8afe52498b7ec0d",
              "IPY_MODEL_858659aedf6e45e780c141d6903b25e4"
            ],
            "layout": "IPY_MODEL_4fb54cf5fa6c4b75965d9fbd7b449ece"
          }
        },
        "ac51f535b479406a9e74620e2e885c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9327df0ece3f423da07db9584419a6b7",
            "placeholder": "​",
            "style": "IPY_MODEL_a97fefff4147405e8e2a4757e4faecf6",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "928c638435d04547a8afe52498b7ec0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67d27d5b59524e6a9ff65564e58f5cfb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87fe5e858b4f4b49a05810867213af01",
            "value": 2
          }
        },
        "858659aedf6e45e780c141d6903b25e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c995b4d87a3c40f2a67aac8ab4905fcc",
            "placeholder": "​",
            "style": "IPY_MODEL_ab75b3bfe1644297962497b113a079c5",
            "value": " 2/2 [00:00&lt;00:00,  2.97it/s]"
          }
        },
        "4fb54cf5fa6c4b75965d9fbd7b449ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "9327df0ece3f423da07db9584419a6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97fefff4147405e8e2a4757e4faecf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67d27d5b59524e6a9ff65564e58f5cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fe5e858b4f4b49a05810867213af01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c995b4d87a3c40f2a67aac8ab4905fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab75b3bfe1644297962497b113a079c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b7d7d61ef9440b9073e2670afa5ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af39083bac504ec2bd56e3d364152a36",
              "IPY_MODEL_a56e24bbf12e48e1995e571caef22075",
              "IPY_MODEL_9d30cab9a73f4bf69e70938ed5f9fe72"
            ],
            "layout": "IPY_MODEL_11421187daed46138be255091ae58e6d"
          }
        },
        "af39083bac504ec2bd56e3d364152a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b51e01688c4176a2928a8f0d7f5e5a",
            "placeholder": "​",
            "style": "IPY_MODEL_c635c7ffa958460e9afbda5312fa9486",
            "value": "Epoch 0:  72%"
          }
        },
        "a56e24bbf12e48e1995e571caef22075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa558b45f1c48c9a354b8a8edb34a7e",
            "max": 194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29c75d710f034455a0a21498a99843bf",
            "value": 140
          }
        },
        "9d30cab9a73f4bf69e70938ed5f9fe72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbe7820e3344d04b3974132f4190719",
            "placeholder": "​",
            "style": "IPY_MODEL_e72110fff52942f6bf5590673f12fc95",
            "value": " 140/194 [01:22&lt;00:31,  1.71it/s, train_loss=-0.959]"
          }
        },
        "11421187daed46138be255091ae58e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "30b51e01688c4176a2928a8f0d7f5e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c635c7ffa958460e9afbda5312fa9486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa558b45f1c48c9a354b8a8edb34a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c75d710f034455a0a21498a99843bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bbe7820e3344d04b3974132f4190719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72110fff52942f6bf5590673f12fc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}