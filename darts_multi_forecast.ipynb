{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cantiusdeepan/Alpine-data-challenge/blob/darts/darts_multi_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install mamba\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFtZVuw-Apk6",
        "outputId": "7e1ab1b7-eda7-43c0-edce-77a833374ca3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting mamba\n",
            "  Downloading mamba-0.11.3.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clint (from mamba)\n",
            "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting coverage (from mamba)\n",
            "  Downloading coverage-7.6.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting args (from clint->mamba)\n",
            "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading coverage-7.6.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mamba, clint, args\n",
            "  Building wheel for mamba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba: filename=mamba-0.11.3-py3-none-any.whl size=16290 sha256=7eea86862a5cae2f3495eb1291f267fe4b7b1ca3e36e0df6675254a6f7a6d2bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/17/87/0c6977b03e2d11fa43ca902080bb7e1d76334f33cfaca2cc34\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34459 sha256=d877706a7a10f5f859db1808755dcad2e9f40de7d1c3ea923988a93642a289fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/8d/f3/91dd49f9a8c6a57be7715f6d11347c49971dd292a53397ed79\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3319 sha256=0e4fbb547dd5bb864cd27c6f9170dd7b2ba9d2475a87d47d58c2e1920401e359\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/a2/87/2541eb895fd18fd20cc7dd18b14d3b61bd9084cf4322abd15e\n",
            "Successfully built mamba clint args\n",
            "Installing collected packages: args, coverage, clint, mamba\n",
            "Successfully installed args-0.1.0 clint-0.5.1 coverage-7.6.12 mamba-0.11.3\n",
            "usage: mamba [-h] [--version] [--slow SLOW] [--enable-coverage] [--coverage-file COVERAGE_FILE]\n",
            "             [--format FORMAT] [--no-color] [--tags TAGS]\n",
            "             [specs ...]\n",
            "mamba: error: unrecognized arguments: -c conda-forge -c pytorch -c nvidia autogluon pytorch=*=*cuda* -y\n",
            "usage: mamba [-h] [--version] [--slow SLOW] [--enable-coverage] [--coverage-file COVERAGE_FILE]\n",
            "             [--format FORMAT] [--no-color] [--tags TAGS]\n",
            "             [specs ...]\n",
            "mamba: error: unrecognized arguments: -c conda-forge ray-tune>=2.10.0,<2.32 ray-default>=2.10.0,<2.32 -y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mamba install 'pytorch=*=*cuda*'\n",
        "!mamba install  'ray-tune>=2.10.0,<2.32' 'ray-default>=2.10.0,<2.32'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V05ICM2CBWom",
        "outputId": "29a7a489-e445-4c80-8f80-99351e8bcd1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[32m\u001b[22m0 examples ran in 0.0000 seconds\u001b[39m\u001b[22m\n",
            "\n",
            "\n",
            "\u001b[32m\u001b[22m0 examples ran in 0.0000 seconds\u001b[39m\u001b[22m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m4SbtP3Bi6g",
        "outputId": "a85b89fe-de6d-4034-ea28-f04e82c7071a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  1 00:06:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXCFESeIAkhM",
        "outputId": "64e8d21a-786c-4709-86c7-74ad741d5eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CUDA available: Tesla T4\n",
            "Memory available: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import logging\n",
        "import os\n",
        "from typing import Dict, List, Optional, Union, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up logging\n",
        "log_dir = './logs'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(log_dir, 'darts_training_alpine_valley.log'),\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        ")\n",
        "\n",
        "# GPU setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    from torch.cuda.amp import GradScaler\n",
        "    scaler = GradScaler(enabled=True)\n",
        "    print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install darts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYgJ9pmMAqIW",
        "outputId": "6e4701c6-5495-4ca3-beb0-5454de46ca37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting darts\n",
            "  Downloading darts-0.33.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from darts) (0.67)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from darts) (3.10.0)\n",
            "Collecting nfoursid>=1.0.0 (from darts)\n",
            "  Downloading nfoursid-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from darts) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from darts) (2.2.2)\n",
            "Collecting pmdarima>=1.8.0 (from darts)\n",
            "  Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
            "Collecting pyod>=0.9.5 (from darts)\n",
            "  Downloading pyod-2.0.3.tar.gz (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.6/169.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from darts) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from darts) (1.13.1)\n",
            "Requirement already satisfied: shap>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.46.0)\n",
            "Collecting statsforecast>=1.4 (from darts)\n",
            "  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from darts) (0.14.4)\n",
            "Collecting tbats>=1.1.0 (from darts)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.11/dist-packages (from darts) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from darts) (4.12.2)\n",
            "Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2025.1.2)\n",
            "Requirement already satisfied: xgboost>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.1.4)\n",
            "Collecting pytorch-lightning>=1.5.0 (from darts)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.1 (from darts)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from darts) (2.5.1+cu124)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from holidays>=0.11.1->darts) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->darts) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->darts) (2025.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (3.0.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (2.3.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=1.8.0->darts) (75.1.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from pyod>=0.9.5->darts) (0.61.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=1.5.0->darts) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts)\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->darts) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.1->darts) (3.5.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.40.0->darts) (3.1.1)\n",
            "Collecting coreforecast>=0.0.12 (from statsforecast>=1.4->darts)\n",
            "  Downloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts)\n",
            "  Downloading utilsforecast-0.2.12-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->darts) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.1->darts) (4.25.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->darts)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->darts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->darts) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (3.11.13)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->holidays>=0.11.1->darts) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->darts) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts) (1.18.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (18.1.0)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Downloading darts-0.33.0-py3-none-any.whl (972 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m972.2/972.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
            "Downloading pmdarima-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.3-py3-none-any.whl size=200466 sha256=ca8aafcdee4ad930a28b55e2ad58bf18e2c9a58586640bbb4355255b66c0abc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/60/5b/f74eccd2c9c892a2c298202ca510f10995f9940647fcc2d97f\n",
            "Successfully built pyod\n",
            "Installing collected packages: appdirs, tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, fs, coreforecast, nvidia-cusparse-cu12, nvidia-cudnn-cu12, utilsforecast, triad, pyod, nvidia-cusolver-cu12, nfoursid, pmdarima, adagio, torchmetrics, tbats, fugue, statsforecast, pytorch-lightning, darts\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed adagio-0.2.6 appdirs-1.4.4 coreforecast-0.0.15 darts-0.33.0 fs-2.4.16 fugue-0.9.1 lightning-utilities-0.12.0 nfoursid-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pmdarima-2.0.4 pyod-2.0.3 pytorch-lightning-2.5.0.post0 statsforecast-2.0.1 tbats-1.1.3 tensorboardX-2.6.2.2 torchmetrics-1.6.1 triad-0.9.8 utilsforecast-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "CrxuS9cJAkhN"
      },
      "outputs": [],
      "source": [
        "# Import Darts components\n",
        "from darts.models import NBEATSModel, BlockRNNModel, TCNModel, TFTModel\n",
        "from darts.metrics import mape, mae, mase\n",
        "from darts import TimeSeries\n",
        "from darts.utils.likelihood_models import GaussianLikelihood\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnmNv35qAkhO",
        "outputId": "1bda9e90-2624-4f1e-d274-743196fa86fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_path: /content/maurienne_valley_20_years_daily_data.csv\n",
            "date_column: Date\n",
            "target_columns: ['Mean Temperature (°C)', 'Min Temperature (°C)', 'Max Temperature (°C)']\n",
            "target_year: 2050\n",
            "valley_ids: ['maurienne']\n",
            "frequency: D\n",
            "model_type: TFTModel\n",
            "input_chunk_length: 365\n",
            "output_chunk_length: 30\n",
            "n_epochs: 100\n",
            "use_covariates: True\n",
            "validation_length: 730\n",
            "random_state: 42\n"
          ]
        }
      ],
      "source": [
        "# Configuration dictionary - adjust as needed\n",
        "CONFIG = {\n",
        "    \"data_path\": \"/content/maurienne_valley_20_years_daily_data.csv\",  # Update with your path\n",
        "    \"date_column\": \"Date\",\n",
        "    \"target_columns\": [\"Mean Temperature (°C)\", \"Min Temperature (°C)\", \"Max Temperature (°C)\"],\n",
        "    \"target_year\": 2050,\n",
        "    \"valley_ids\": [\"maurienne\"],  # Add \"susa\" when using data from both valleys\n",
        "    \"frequency\": \"D\",  # \"D\" for daily, \"M\" for monthly\n",
        "    \"model_type\": \"TFTModel\",  # Options: \"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"\n",
        "    \"input_chunk_length\": 365,  # Lookback window (1 year of daily data)\n",
        "    \"output_chunk_length\": 30,  # Output window (1 month of daily data)\n",
        "    \"n_epochs\": 100,\n",
        "    \"use_covariates\": True,\n",
        "    \"validation_length\": 365 * 2,  # 2 years of daily data\n",
        "    \"random_state\": 42,\n",
        "}\n",
        "\n",
        "# Display configuration for review\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "SVrMSDyaAkhO"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster:\n",
        "    def __init__(self, config: Dict) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the WeatherForecaster with the given configuration.\n",
        "\n",
        "        Args:\n",
        "            config (Dict): Configuration dictionary containing parameters for data loading,\n",
        "                           model training, and forecasting.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.scalers = {}\n",
        "        self.full_history = None\n",
        "        self.covariates = None\n",
        "\n",
        "    def _load_data(self) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Load and preprocess time series data.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary mapping valley IDs to TimeSeries objects.\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(self.config[\"data_path\"])\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[self.config[\"date_column\"]])\n",
        "\n",
        "        series_dict = {}\n",
        "        for valley_id in self.config[\"valley_ids\"]:\n",
        "            # Filter data for this valley if needed\n",
        "            valley_df = df[df[\"item_id\"] == valley_id] if \"item_id\" in df.columns else df\n",
        "\n",
        "            # Select target columns\n",
        "            target_cols = self.config[\"target_columns\"]\n",
        "            valley_df = valley_df[[\"timestamp\"] + target_cols]\n",
        "\n",
        "            # Convert to Darts TimeSeries\n",
        "            ts = TimeSeries.from_dataframe(\n",
        "                valley_df,\n",
        "                time_col=\"timestamp\",\n",
        "                value_cols=target_cols\n",
        "            )\n",
        "            series_dict[valley_id] = ts\n",
        "\n",
        "        return series_dict\n",
        "\n",
        "    def _generate_covariates(self, series_dict: Dict[str, TimeSeries]) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Generate covariates for forecasting such as year, month, and day of year.\n",
        "\n",
        "        Args:\n",
        "            series_dict (Dict[str, TimeSeries]): Dictionary of time series data.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary of covariate time series.\n",
        "        \"\"\"\n",
        "        covariates_dict = {}\n",
        "        for valley_id, ts in series_dict.items():\n",
        "            # Create year and month covariates\n",
        "            year_series = datetime_attribute_timeseries(ts, attribute=\"year\")\n",
        "            month_series = datetime_attribute_timeseries(ts, attribute=\"month\")\n",
        "            day_of_year_series = datetime_attribute_timeseries(ts, attribute=\"dayofyear\")\n",
        "\n",
        "            # Normalize covariates\n",
        "            scaler = Scaler()\n",
        "            year_series = scaler.fit_transform(year_series)\n",
        "            month_series = scaler.fit_transform(month_series)\n",
        "            day_of_year_series = scaler.fit_transform(day_of_year_series)\n",
        "\n",
        "            # Stack covariates\n",
        "            covariates = year_series.stack(month_series).stack(day_of_year_series)\n",
        "            covariates_dict[valley_id] = covariates\n",
        "\n",
        "        return covariates_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Nd3xORKzAkhO",
        "outputId": "2f8402a8-c99d-4aad-e8a0-96e73324b509"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (<ipython-input-15-f60349a3663b>, line 76)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-f60349a3663b>\"\u001b[0;36m, line \u001b[0;32m76\u001b[0m\n\u001b[0;31m    \"add_relative_index\": True,\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _preprocess_data(self, series_dict: Dict[str, TimeSeries]) -> Tuple[Dict[str, TimeSeries], Dict[str, TimeSeries]]:\n",
        "        \"\"\"\n",
        "        Preprocess time series data, including scaling and train/validation split.\n",
        "\n",
        "        Args:\n",
        "            series_dict (Dict[str, TimeSeries]): Dictionary of time series data.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Dict[str, TimeSeries], Dict[str, TimeSeries]]: Dictionaries of scaled training and validation series.\n",
        "        \"\"\"\n",
        "        train_dict = {}\n",
        "        val_dict = {}\n",
        "\n",
        "        for valley_id, ts in series_dict.items():\n",
        "            # Split into training and validation\n",
        "            val_length = self.config.get(\"validation_length\", 24)  # 2 years of monthly data by default\n",
        "            train_ts, val_ts = ts[:-val_length], ts[-val_length:]\n",
        "\n",
        "            # Scale the data\n",
        "            scaler = Scaler()\n",
        "            train_ts_scaled = scaler.fit_transform(train_ts)\n",
        "            val_ts_scaled = scaler.transform(val_ts)\n",
        "\n",
        "            # Store the scaler for later use\n",
        "            self.scalers[valley_id] = scaler\n",
        "\n",
        "            train_dict[valley_id] = train_ts_scaled\n",
        "            val_dict[valley_id] = val_ts_scaled\n",
        "\n",
        "        return train_dict, val_dict\n",
        "\n",
        "    def _create_model(self) -> Union[NBEATSModel, BlockRNNModel, TCNModel, TFTModel]:\n",
        "        \"\"\"\n",
        "        Create and return a forecasting model based on configuration.\n",
        "\n",
        "        Returns:\n",
        "            A Darts forecasting model configured for probabilistic forecasting.\n",
        "        \"\"\"\n",
        "        model_type = self.config.get(\"model_type\", \"NBEATSModel\")\n",
        "        input_chunk_length = self.config.get(\"input_chunk_length\", 24)\n",
        "        output_chunk_length = self.config.get(\"output_chunk_length\", 12)\n",
        "        n_epochs = self.config.get(\"n_epochs\", 100)\n",
        "\n",
        "        # Common parameters for all models\n",
        "        common_params = {\n",
        "            \"input_chunk_length\": input_chunk_length,\n",
        "            \"output_chunk_length\": output_chunk_length,\n",
        "            \"n_epochs\": n_epochs,\n",
        "            \"random_state\": self.config.get(\"random_state\", 42),\n",
        "            \"likelihood\": GaussianLikelihood(),  # For probabilistic forecasts\n",
        "            \"force_reset\": True,\n",
        "            \"pl_trainer_kwargs\": {\n",
        "                \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
        "                \"devices\": 1,\n",
        "                \"log_every_n_steps\": 10,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if model_type == \"NBEATSModel\":\n",
        "            return NBEATSModel(**common_params)\n",
        "        elif model_type == \"BlockRNNModel\":\n",
        "            return BlockRNNModel(\n",
        "                model=self.config.get(\"rnn_type\", \"LSTM\"),\n",
        "                **common_params\n",
        "            )\n",
        "        elif model_type == \"TCNModel\":\n",
        "            return TCNModel(**common_params)\n",
        "        elif model_type == \"TFTModel\":\n",
        "            return TFTModel(\n",
        "                hidden_size=self.config.get(\"hidden_size\", 64),\n",
        "                lstm_layers=self.config.get(\"lstm_layers\", 1),\n",
        "                num_attention_heads=self.config.get(\"num_attention_heads\", 4),\n",
        "                dropout=self.config.get(\"dropout\", 0.1),\n",
        "\n",
        "        add_relative_index=True,\n",
        "                **common_params\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ZMyDQeWYAkhO"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _train_model(self, train_dict: Dict[str, TimeSeries], val_dict: Dict[str, TimeSeries]) -> None:\n",
        "        \"\"\"\n",
        "        Train the model on the given data.\n",
        "\n",
        "        Args:\n",
        "            train_dict (Dict[str, TimeSeries]): Dictionary of training time series.\n",
        "            val_dict (Dict[str, TimeSeries]): Dictionary of validation time series.\n",
        "        \"\"\"\n",
        "        # Create model\n",
        "        self.model = self._create_model()\n",
        "\n",
        "        # Convert dictionaries to lists for model.fit()\n",
        "        train_series = list(train_dict.values())\n",
        "        val_series = list(val_dict.values())\n",
        "\n",
        "        # Generate covariates if specified\n",
        "        if self.config.get(\"use_covariates\", True):\n",
        "            self.covariates = self._generate_covariates({**train_dict, **val_dict})\n",
        "            covariates_list = list(self.covariates.values())\n",
        "\n",
        "            # Train with covariates\n",
        "            self.model.fit(\n",
        "                series=train_series,\n",
        "                past_covariates=covariates_list,\n",
        "                val_series=val_series,\n",
        "                val_past_covariates=covariates_list,\n",
        "                verbose=True\n",
        "            )\n",
        "        else:\n",
        "            # Train without covariates\n",
        "            self.model.fit(\n",
        "                series=train_series,\n",
        "                val_series=val_series,\n",
        "                verbose=True\n",
        "            )\n",
        "\n",
        "        logging.info(f\"Model training completed: {self.model}\")\n",
        "\n",
        "    def _forecast(self, train_dict: Dict[str, TimeSeries], horizon: int) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Generate forecasts for the specified horizon.\n",
        "\n",
        "        Args:\n",
        "            train_dict (Dict[str, TimeSeries]): Dictionary of training time series.\n",
        "            horizon (int): Forecast horizon in time steps.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary of forecast time series with probabilistic samples.\n",
        "        \"\"\"\n",
        "        forecasts = {}\n",
        "\n",
        "        for valley_id, ts in train_dict.items():\n",
        "            if self.config.get(\"use_covariates\", True) and self.covariates:\n",
        "                # Forecast with covariates\n",
        "                forecast = self.model.predict(\n",
        "                    n=horizon,\n",
        "                    series=ts,\n",
        "                    past_covariates=self.covariates[valley_id],\n",
        "                    num_samples=100  # For probabilistic forecasts\n",
        "                )\n",
        "            else:\n",
        "                # Forecast without covariates\n",
        "                forecast = self.model.predict(\n",
        "                    n=horizon,\n",
        "                    series=ts,\n",
        "                    num_samples=100  # For probabilistic forecasts\n",
        "                )\n",
        "\n",
        "            # Inverse transform the forecast\n",
        "            forecast = self.scalers[valley_id].inverse_transform(forecast)\n",
        "            forecasts[valley_id] = forecast\n",
        "\n",
        "        return forecasts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "u0E35YA8AkhP"
      },
      "outputs": [],
      "source": [
        "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
        "    def _plot_forecasts(self,\n",
        "                        full_series: Dict[str, TimeSeries],\n",
        "                        forecasts: Dict[str, TimeSeries],\n",
        "                        val_series: Optional[Dict[str, TimeSeries]] = None) -> None:\n",
        "        \"\"\"\n",
        "        Plot forecasts with confidence intervals for each feature.\n",
        "\n",
        "        Args:\n",
        "            full_series (Dict[str, TimeSeries]): Dictionary of full historical time series.\n",
        "            forecasts (Dict[str, TimeSeries]): Dictionary of forecast time series.\n",
        "            val_series (Optional[Dict[str, TimeSeries]]): Dictionary of validation time series.\n",
        "        \"\"\"\n",
        "        feature_colors = {\n",
        "            \"Mean Temperature (°C)\": \"red\",\n",
        "            \"Min Temperature (°C)\": \"blue\",\n",
        "            \"Max Temperature (°C)\": \"green\",\n",
        "            # Add more features as needed\n",
        "        }\n",
        "\n",
        "        for valley_id in full_series.keys():\n",
        "            # Get feature names for this valley\n",
        "            feature_names = full_series[valley_id].components\n",
        "\n",
        "            # Plot each feature separately\n",
        "            for i, feature in enumerate(feature_names):\n",
        "                plt.figure(figsize=(15, 8))\n",
        "\n",
        "                # Plot historical data\n",
        "                hist_series = full_series[valley_id].univariate_component(i)\n",
        "                hist_series.plot(label=f\"{valley_id} - {feature} (Actual)\", color=feature_colors.get(feature, \"blue\"))\n",
        "\n",
        "                # Plot validation data if provided\n",
        "                if val_series and valley_id in val_series:\n",
        "                    val_data = val_series[valley_id].univariate_component(i)\n",
        "                    val_data.plot(label=f\"{valley_id} - {feature} (Validation)\", color=\"purple\", linestyle=\"--\")\n",
        "\n",
        "                # Plot forecast with confidence intervals\n",
        "                forecast = forecasts[valley_id].univariate_component(i)\n",
        "                forecast.plot(label=f\"{valley_id} - {feature} (Forecast)\", color=\"orange\")\n",
        "\n",
        "                # Plot confidence intervals if this is a probabilistic forecast\n",
        "                if forecast.n_samples > 1:\n",
        "                    p10, p90 = forecast.quantiles_timeseries(0.1, 0.9)\n",
        "                    plt.fill_between(\n",
        "                        forecast.time_index,\n",
        "                        p10.values().flatten(),\n",
        "                        p90.values().flatten(),\n",
        "                        alpha=0.2,\n",
        "                        color=\"orange\",\n",
        "                        label=\"80% Confidence Interval\"\n",
        "                    )\n",
        "\n",
        "                plt.title(f\"{feature} Forecast for {valley_id} Valley until {self.config['target_year']}\")\n",
        "                plt.xlabel(\"Year\")\n",
        "                plt.ylabel(feature)\n",
        "                plt.legend()\n",
        "                plt.grid(True)\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # In Colab, display the plot\n",
        "                plt.show()\n",
        "\n",
        "                # Save the plot to file\n",
        "                plt.savefig(f\"{valley_id}_{feature.replace(' ', '_')}_forecast.png\")\n",
        "                plt.close()\n",
        "\n",
        "                logging.info(f\"Plot saved for {valley_id} - {feature}\")\n",
        "\n",
        "    def run_pipeline(self) -> Dict[str, TimeSeries]:\n",
        "        \"\"\"\n",
        "        Main execution flow for the forecasting pipeline.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, TimeSeries]: Dictionary of forecast time series.\n",
        "        \"\"\"\n",
        "        # Load data\n",
        "        series_dict = self._load_data()\n",
        "        self.full_history = series_dict\n",
        "\n",
        "        # Preprocess data\n",
        "        train_dict, val_dict = self._preprocess_data(series_dict)\n",
        "\n",
        "        # Train model\n",
        "        self._train_model(train_dict, val_dict)\n",
        "\n",
        "        # Calculate forecast horizon\n",
        "        sample_ts = list(series_dict.values())[0]\n",
        "        forecast_end_year = self.config[\"target_year\"]\n",
        "        current_end_year = sample_ts.time_index[-1].year\n",
        "        years_to_forecast = forecast_end_year - current_end_year\n",
        "\n",
        "        # Convert years to number of time steps based on data frequency\n",
        "        steps_per_year = 12  # Assuming monthly data\n",
        "        if self.config.get(\"frequency\") == \"D\":\n",
        "            steps_per_year = 365\n",
        "        horizon = years_to_forecast * steps_per_year\n",
        "\n",
        "        print(f\"Forecasting {years_to_forecast} years ahead ({horizon} time steps)\")\n",
        "\n",
        "        # Generate forecasts\n",
        "        forecasts = self._forecast(train_dict, horizon)\n",
        "\n",
        "        # Plot results\n",
        "        self._plot_forecasts(self.full_history, forecasts, val_dict)\n",
        "\n",
        "        return forecasts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "POqfGFncAkhP",
        "outputId": "ccc21233-455a-438d-bfbc-76be842e3bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:darts.models.forecasting.tft_model:ValueError: TFTModel requires future covariates. The model applies multi-head attention queries on future inputs. Consider specifying a future encoder with `add_encoders` or setting `add_relative_index` to `True` at model creation (read TFT model docs for more information). These will automatically generate `future_covariates` from indexes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "TFTModel requires future covariates. The model applies multi-head attention queries on future inputs. Consider specifying a future encoder with `add_encoders` or setting `add_relative_index` to `True` at model creation (read TFT model docs for more information). These will automatically generate `future_covariates` from indexes.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-757d29a257bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create and run the forecaster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mforecaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeatherForecaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Forecasting complete. Results saved as PNG files.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e7b47e2ddf03>\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Calculate forecast horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6bfaa1a30b78>\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, train_dict, val_dict)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Train with covariates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             self.model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mseries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_series\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mpast_covariates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovariates_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/utils/torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, dataloader_kwargs, sample_weight, val_sample_weight)\u001b[0m\n\u001b[1;32m    751\u001b[0m             ),\n\u001b[1;32m    752\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_for_fit_from_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0mseries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mpast_covariates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_covariates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36m_setup_for_fit_from_dataset\u001b[0;34m(self, series, past_covariates, future_covariates, sample_weight, val_series, val_past_covariates, val_future_covariates, val_sample_weight, trainer, verbose, epochs, max_samples_per_ts, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m         )\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         train_dataset = self._build_train_dataset(\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mpast_covariates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_covariates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/models/forecasting/tft_model.py\u001b[0m in \u001b[0;36m_build_train_dataset\u001b[0;34m(self, target, past_covariates, future_covariates, sample_weight, max_samples_per_ts)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mmax_samples_per_ts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     ) -> MixedCovariatesSequentialDataset:\n\u001b[0;32m-> 1166\u001b[0;31m         raise_if(\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mfuture_covariates\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_relative_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;34m\"TFTModel requires future covariates. The model applies multi-head attention queries on future \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/logging.py\u001b[0m in \u001b[0;36mraise_if\u001b[0;34m(condition, message, logger)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msatisfied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mraise_if_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/darts/logging.py\u001b[0m in \u001b[0;36mraise_if_not\u001b[0;34m(condition, message, logger)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ValueError: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: TFTModel requires future covariates. The model applies multi-head attention queries on future inputs. Consider specifying a future encoder with `add_encoders` or setting `add_relative_index` to `True` at model creation (read TFT model docs for more information). These will automatically generate `future_covariates` from indexes."
          ]
        }
      ],
      "source": [
        "# Create and run the forecaster\n",
        "forecaster = WeatherForecaster(CONFIG)\n",
        "results = forecaster.run_pipeline()\n",
        "print(f\"Forecasting complete. Results saved as PNG files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "53Rs3-zIAkhP"
      },
      "outputs": [],
      "source": [
        "# Optional: Compare different models\n",
        "def compare_models(config, target_columns=None):\n",
        "    \"\"\"Compare performance of different models on the dataset.\"\"\"\n",
        "    if target_columns is None:\n",
        "        target_columns = config[\"target_columns\"][:1]  # Just use first target for comparison\n",
        "\n",
        "    model_types = [\"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"]\n",
        "    results = {}\n",
        "\n",
        "    for model_type in model_types:\n",
        "        print(f\"\\nTraining {model_type}...\")\n",
        "\n",
        "        # Update config with current model\n",
        "        test_config = config.copy()\n",
        "        test_config[\"model_type\"] = model_type\n",
        "        test_config[\"target_columns\"] = target_columns\n",
        "        test_config[\"n_epochs\"] = 20  # Reduced for comparison\n",
        "\n",
        "        try:\n",
        "            forecaster = WeatherForecaster(test_config)\n",
        "            # Load data\n",
        "            series_dict = forecaster._load_data()\n",
        "            # Preprocess data\n",
        "            train_dict, val_dict = forecaster._preprocess_data(series_dict)\n",
        "            # Train model\n",
        "            forecaster._train_model(train_dict, val_dict)\n",
        "\n",
        "            # Calculate validation metrics\n",
        "            val_metrics = {}\n",
        "            for valley_id in val_dict.keys():\n",
        "                val_true = forecaster.scalers[valley_id].inverse_transform(val_dict[valley_id])\n",
        "\n",
        "                # Generate predictions for validation period\n",
        "                val_pred = forecaster.model.predict(\n",
        "                    n=len(val_true),\n",
        "                    series=train_dict[valley_id],\n",
        "                    past_covariates=forecaster.covariates[valley_id] if forecaster.covariates else None\n",
        "                )\n",
        "                val_pred = forecaster.scalers[valley_id].inverse_transform(val_pred)\n",
        "\n",
        "                # Calculate metrics\n",
        "                mae_val = mae(val_true, val_pred)\n",
        "                mape_val = mape(val_true, val_pred)\n",
        "                val_metrics[valley_id] = {\"MAE\": mae_val, \"MAPE\": mape_val}\n",
        "\n",
        "            results[model_type] = val_metrics\n",
        "            print(f\"{model_type} validation metrics: {val_metrics}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {model_type}: {str(e)}\")\n",
        "            results[model_type] = {\"error\": str(e)}\n",
        "\n",
        "    # Display comparison table\n",
        "    comparison_df = pd.DataFrame({\n",
        "        model: {f\"{valley_id}_MAE\": metrics.get(valley_id, {}).get(\"MAE\", None)\n",
        "                for valley_id in config[\"valley_ids\"]}\n",
        "        for model, metrics in results.items()\n",
        "    })\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "# Uncomment to run model comparison\n",
        "# model_comparison = compare_models(CONFIG)\n",
        "# model_comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "LihdW4g4AkhP"
      },
      "outputs": [],
      "source": [
        "def multistation_approach_example():\n",
        "    \"\"\"\n",
        "    Example of different approaches to handle multiple weather stations and valleys.\n",
        "    Showing code structure without actual implementation.\n",
        "    \"\"\"\n",
        "    print(\"Three main approaches for handling multiple valleys/stations:\")\n",
        "\n",
        "    # Approach 1: Item ID approach (like in the main code)\n",
        "    print(\"\\n1. Item ID Approach:\")\n",
        "    print(\"- Each valley/station is treated as a separate time series\")\n",
        "    print(\"- Advantage: Simple, allows different scaling per station\")\n",
        "    print(\"- Implementation: Already shown in main code\")\n",
        "\n",
        "    # Approach 2: Multivariate approach\n",
        "    print(\"\\n2. Multivariate Approach:\")\n",
        "    print(\"- All features from all stations in one multivariate time series\")\n",
        "    print(\"- Advantage: Model learns correlations between stations\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    # Example implementation (pseudocode):\n",
        "    def load_multivariate_data():\n",
        "        # Load data from all stations\n",
        "        all_stations_df = []\n",
        "        for station in stations:\n",
        "            df = pd.read_csv(f\"{station}_data.csv\")\n",
        "            # Rename columns to include station\n",
        "            for col in feature_columns:\n",
        "                df.rename(columns={col: f\"{col}_{station}\"}, inplace=True)\n",
        "            all_stations_df.append(df)\n",
        "\n",
        "        # Merge on timestamp\n",
        "        merged_df = pd.merge(all_stations_df, on=\"timestamp\")\n",
        "\n",
        "        # Convert to Darts TimeSeries\n",
        "        ts = TimeSeries.from_dataframe(\n",
        "            merged_df,\n",
        "            time_col=\"timestamp\",\n",
        "            value_cols=[f\"{col}_{station}\" for col in feature_columns for station in stations]\n",
        "        )\n",
        "        return ts\n",
        "    \"\"\")\n",
        "\n",
        "    # Approach 3: One-hot encoding approach\n",
        "    print(\"\\n3. One-hot Encoding Approach:\")\n",
        "    print(\"- Add station/valley identifiers as one-hot encoded features\")\n",
        "    print(\"- Advantage: Allows model to learn location-specific patterns\")\n",
        "\n",
        "    print(\"\"\"\n",
        "    # Example implementation (pseudocode):\n",
        "    def generate_station_covariates(ts, station_id):\n",
        "        # Create one-hot encoding for stations\n",
        "        station_ids = [\"station1\", \"station2\", \"station3\", \"station4\"]\n",
        "        one_hot = [1 if station_id == sid else 0 for sid in station_ids]\n",
        "\n",
        "        # Create covariates TimeSeries with same time index\n",
        "        covariates_data = np.tile(one_hot, (len(ts), 1))\n",
        "        covariates = TimeSeries.from_values(covariates_data, index=ts.time_index)\n",
        "\n",
        "        return covariates\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\nRecommendation: Use multivariate approach for stations within the same valley,\")\n",
        "    print(\"and item_id approach for different valleys.\")\n",
        "\n",
        "# multistation_approach_example()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}