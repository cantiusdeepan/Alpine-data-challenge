{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, List, Optional, Union, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up logging\n",
    "log_dir = './logs'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(log_dir, 'darts_training_alpine_valley.log'),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    from torch.cuda.amp import GradScaler\n",
    "    scaler = GradScaler(enabled=True)\n",
    "    print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import Darts components\n",
    "from darts.models import NBEATSModel, BlockRNNModel, TCNModel, TFTModel\n",
    "from darts.metrics import mape, mae, mase\n",
    "from darts import TimeSeries\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration dictionary - adjust as needed\n",
    "CONFIG = {\n",
    "    \"data_path\": \"./data/maurienne_valley_20_years_daily_data.csv\",  # Update with your path\n",
    "    \"date_column\": \"Date\",\n",
    "    \"target_columns\": [\"Mean Temperature (°C)\", \"Min Temperature (°C)\", \"Max Temperature (°C)\"],\n",
    "    \"target_year\": 2050,\n",
    "    \"valley_ids\": [\"maurienne\"],  # Add \"susa\" when using data from both valleys\n",
    "    \"frequency\": \"D\",  # \"D\" for daily, \"M\" for monthly\n",
    "    \"model_type\": \"NBEATSModel\",  # Options: \"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"\n",
    "    \"input_chunk_length\": 365,  # Lookback window (1 year of daily data)\n",
    "    \"output_chunk_length\": 30,  # Output window (1 month of daily data)\n",
    "    \"n_epochs\": 100,\n",
    "    \"use_covariates\": True,\n",
    "    \"validation_length\": 365 * 2,  # 2 years of daily data\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "# Display configuration for review\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WeatherForecaster:\n",
    "    def __init__(self, config: Dict) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the WeatherForecaster with the given configuration.\n",
    "\n",
    "        Args:\n",
    "            config (Dict): Configuration dictionary containing parameters for data loading,\n",
    "                           model training, and forecasting.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.scalers = {}\n",
    "        self.full_history = None\n",
    "        self.covariates = None\n",
    "\n",
    "    def _load_data(self) -> Dict[str, TimeSeries]:\n",
    "        \"\"\"\n",
    "        Load and preprocess time series data.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, TimeSeries]: Dictionary mapping valley IDs to TimeSeries objects.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.config[\"data_path\"])\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[self.config[\"date_column\"]])\n",
    "\n",
    "        series_dict = {}\n",
    "        for valley_id in self.config[\"valley_ids\"]:\n",
    "            # Filter data for this valley if needed\n",
    "            valley_df = df[df[\"item_id\"] == valley_id] if \"item_id\" in df.columns else df\n",
    "\n",
    "            # Select target columns\n",
    "            target_cols = self.config[\"target_columns\"]\n",
    "            valley_df = valley_df[[\"timestamp\"] + target_cols]\n",
    "\n",
    "            # Convert to Darts TimeSeries\n",
    "            ts = TimeSeries.from_dataframe(\n",
    "                valley_df,\n",
    "                time_col=\"timestamp\",\n",
    "                value_cols=target_cols\n",
    "            )\n",
    "            series_dict[valley_id] = ts\n",
    "\n",
    "        return series_dict\n",
    "\n",
    "    def _generate_covariates(self, series_dict: Dict[str, TimeSeries]) -> Dict[str, TimeSeries]:\n",
    "        \"\"\"\n",
    "        Generate covariates for forecasting such as year, month, and day of year.\n",
    "\n",
    "        Args:\n",
    "            series_dict (Dict[str, TimeSeries]): Dictionary of time series data.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, TimeSeries]: Dictionary of covariate time series.\n",
    "        \"\"\"\n",
    "        covariates_dict = {}\n",
    "        for valley_id, ts in series_dict.items():\n",
    "            # Create year and month covariates\n",
    "            year_series = datetime_attribute_timeseries(ts, attribute=\"year\")\n",
    "            month_series = datetime_attribute_timeseries(ts, attribute=\"month\")\n",
    "            day_of_year_series = datetime_attribute_timeseries(ts, attribute=\"dayofyear\")\n",
    "\n",
    "            # Normalize covariates\n",
    "            scaler = Scaler()\n",
    "            year_series = scaler.fit_transform(year_series)\n",
    "            month_series = scaler.fit_transform(month_series)\n",
    "            day_of_year_series = scaler.fit_transform(day_of_year_series)\n",
    "\n",
    "            # Stack covariates\n",
    "            covariates = year_series.stack(month_series).stack(day_of_year_series)\n",
    "            covariates_dict[valley_id] = covariates\n",
    "\n",
    "        return covariates_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
    "    def _preprocess_data(self, series_dict: Dict[str, TimeSeries]) -> Tuple[Dict[str, TimeSeries], Dict[str, TimeSeries]]:\n",
    "        \"\"\"\n",
    "        Preprocess time series data, including scaling and train/validation split.\n",
    "\n",
    "        Args:\n",
    "            series_dict (Dict[str, TimeSeries]): Dictionary of time series data.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict[str, TimeSeries], Dict[str, TimeSeries]]: Dictionaries of scaled training and validation series.\n",
    "        \"\"\"\n",
    "        train_dict = {}\n",
    "        val_dict = {}\n",
    "\n",
    "        for valley_id, ts in series_dict.items():\n",
    "            # Split into training and validation\n",
    "            val_length = self.config.get(\"validation_length\", 24)  # 2 years of monthly data by default\n",
    "            train_ts, val_ts = ts[:-val_length], ts[-val_length:]\n",
    "\n",
    "            # Scale the data\n",
    "            scaler = Scaler()\n",
    "            train_ts_scaled = scaler.fit_transform(train_ts)\n",
    "            val_ts_scaled = scaler.transform(val_ts)\n",
    "\n",
    "            # Store the scaler for later use\n",
    "            self.scalers[valley_id] = scaler\n",
    "\n",
    "            train_dict[valley_id] = train_ts_scaled\n",
    "            val_dict[valley_id] = val_ts_scaled\n",
    "\n",
    "        return train_dict, val_dict\n",
    "\n",
    "    def _create_model(self) -> Union[NBEATSModel, BlockRNNModel, TCNModel, TFTModel]:\n",
    "        \"\"\"\n",
    "        Create and return a forecasting model based on configuration.\n",
    "\n",
    "        Returns:\n",
    "            A Darts forecasting model configured for probabilistic forecasting.\n",
    "        \"\"\"\n",
    "        model_type = self.config.get(\"model_type\", \"NBEATSModel\")\n",
    "        input_chunk_length = self.config.get(\"input_chunk_length\", 24)\n",
    "        output_chunk_length = self.config.get(\"output_chunk_length\", 12)\n",
    "        n_epochs = self.config.get(\"n_epochs\", 100)\n",
    "\n",
    "        # Common parameters for all models\n",
    "        common_params = {\n",
    "            \"input_chunk_length\": input_chunk_length,\n",
    "            \"output_chunk_length\": output_chunk_length,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"random_state\": self.config.get(\"random_state\", 42),\n",
    "            \"likelihood\": GaussianLikelihood(),  # For probabilistic forecasts\n",
    "            \"force_reset\": True,\n",
    "            \"pl_trainer_kwargs\": {\n",
    "                \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                \"devices\": 1,\n",
    "                \"log_every_n_steps\": 10,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if model_type == \"NBEATSModel\":\n",
    "            return NBEATSModel(**common_params)\n",
    "        elif model_type == \"BlockRNNModel\":\n",
    "            return BlockRNNModel(\n",
    "                model=self.config.get(\"rnn_type\", \"LSTM\"),\n",
    "                **common_params\n",
    "            )\n",
    "        elif model_type == \"TCNModel\":\n",
    "            return TCNModel(**common_params)\n",
    "        elif model_type == \"TFTModel\":\n",
    "            return TFTModel(\n",
    "                hidden_size=self.config.get(\"hidden_size\", 64),\n",
    "                lstm_layers=self.config.get(\"lstm_layers\", 1),\n",
    "                num_attention_heads=self.config.get(\"num_attention_heads\", 4),\n",
    "                dropout=self.config.get(\"dropout\", 0.1),\n",
    "                **common_params\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
    "    def _train_model(self, train_dict: Dict[str, TimeSeries], val_dict: Dict[str, TimeSeries]) -> None:\n",
    "        \"\"\"\n",
    "        Train the model on the given data.\n",
    "\n",
    "        Args:\n",
    "            train_dict (Dict[str, TimeSeries]): Dictionary of training time series.\n",
    "            val_dict (Dict[str, TimeSeries]): Dictionary of validation time series.\n",
    "        \"\"\"\n",
    "        # Create model\n",
    "        self.model = self._create_model()\n",
    "\n",
    "        # Convert dictionaries to lists for model.fit()\n",
    "        train_series = list(train_dict.values())\n",
    "        val_series = list(val_dict.values())\n",
    "\n",
    "        # Generate covariates if specified\n",
    "        if self.config.get(\"use_covariates\", True):\n",
    "            self.covariates = self._generate_covariates({**train_dict, **val_dict})\n",
    "            covariates_list = list(self.covariates.values())\n",
    "\n",
    "            # Train with covariates\n",
    "            self.model.fit(\n",
    "                series=train_series,\n",
    "                past_covariates=covariates_list,\n",
    "                val_series=val_series,\n",
    "                val_past_covariates=covariates_list,\n",
    "                verbose=True\n",
    "            )\n",
    "        else:\n",
    "            # Train without covariates\n",
    "            self.model.fit(\n",
    "                series=train_series,\n",
    "                val_series=val_series,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "        logging.info(f\"Model training completed: {self.model}\")\n",
    "\n",
    "    def _forecast(self, train_dict: Dict[str, TimeSeries], horizon: int) -> Dict[str, TimeSeries]:\n",
    "        \"\"\"\n",
    "        Generate forecasts for the specified horizon.\n",
    "\n",
    "        Args:\n",
    "            train_dict (Dict[str, TimeSeries]): Dictionary of training time series.\n",
    "            horizon (int): Forecast horizon in time steps.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, TimeSeries]: Dictionary of forecast time series with probabilistic samples.\n",
    "        \"\"\"\n",
    "        forecasts = {}\n",
    "\n",
    "        for valley_id, ts in train_dict.items():\n",
    "            if self.config.get(\"use_covariates\", True) and self.covariates:\n",
    "                # Forecast with covariates\n",
    "                forecast = self.model.predict(\n",
    "                    n=horizon,\n",
    "                    series=ts,\n",
    "                    past_covariates=self.covariates[valley_id],\n",
    "                    num_samples=100  # For probabilistic forecasts\n",
    "                )\n",
    "            else:\n",
    "                # Forecast without covariates\n",
    "                forecast = self.model.predict(\n",
    "                    n=horizon,\n",
    "                    series=ts,\n",
    "                    num_samples=100  # For probabilistic forecasts\n",
    "                )\n",
    "\n",
    "            # Inverse transform the forecast\n",
    "            forecast = self.scalers[valley_id].inverse_transform(forecast)\n",
    "            forecasts[valley_id] = forecast\n",
    "\n",
    "        return forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class WeatherForecaster(WeatherForecaster):  # Continuing the class definition\n",
    "    def _plot_forecasts(self,\n",
    "                        full_series: Dict[str, TimeSeries],\n",
    "                        forecasts: Dict[str, TimeSeries],\n",
    "                        val_series: Optional[Dict[str, TimeSeries]] = None) -> None:\n",
    "        \"\"\"\n",
    "        Plot forecasts with confidence intervals for each feature.\n",
    "\n",
    "        Args:\n",
    "            full_series (Dict[str, TimeSeries]): Dictionary of full historical time series.\n",
    "            forecasts (Dict[str, TimeSeries]): Dictionary of forecast time series.\n",
    "            val_series (Optional[Dict[str, TimeSeries]]): Dictionary of validation time series.\n",
    "        \"\"\"\n",
    "        feature_colors = {\n",
    "            \"Mean Temperature (°C)\": \"red\",\n",
    "            \"Min Temperature (°C)\": \"blue\",\n",
    "            \"Max Temperature (°C)\": \"green\",\n",
    "            # Add more features as needed\n",
    "        }\n",
    "\n",
    "        for valley_id in full_series.keys():\n",
    "            # Get feature names for this valley\n",
    "            feature_names = full_series[valley_id].components\n",
    "\n",
    "            # Plot each feature separately\n",
    "            for i, feature in enumerate(feature_names):\n",
    "                plt.figure(figsize=(15, 8))\n",
    "\n",
    "                # Plot historical data\n",
    "                hist_series = full_series[valley_id].univariate_component(i)\n",
    "                hist_series.plot(label=f\"{valley_id} - {feature} (Actual)\", color=feature_colors.get(feature, \"blue\"))\n",
    "\n",
    "                # Plot validation data if provided\n",
    "                if val_series and valley_id in val_series:\n",
    "                    val_data = val_series[valley_id].univariate_component(i)\n",
    "                    val_data.plot(label=f\"{valley_id} - {feature} (Validation)\", color=\"purple\", linestyle=\"--\")\n",
    "\n",
    "                # Plot forecast with confidence intervals\n",
    "                forecast = forecasts[valley_id].univariate_component(i)\n",
    "                forecast.plot(label=f\"{valley_id} - {feature} (Forecast)\", color=\"orange\")\n",
    "\n",
    "                # Plot confidence intervals if this is a probabilistic forecast\n",
    "                if forecast.n_samples > 1:\n",
    "                    p10, p90 = forecast.quantiles_timeseries(0.1, 0.9)\n",
    "                    plt.fill_between(\n",
    "                        forecast.time_index,\n",
    "                        p10.values().flatten(),\n",
    "                        p90.values().flatten(),\n",
    "                        alpha=0.2,\n",
    "                        color=\"orange\",\n",
    "                        label=\"80% Confidence Interval\"\n",
    "                    )\n",
    "\n",
    "                plt.title(f\"{feature} Forecast for {valley_id} Valley until {self.config['target_year']}\")\n",
    "                plt.xlabel(\"Year\")\n",
    "                plt.ylabel(feature)\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # In Colab, display the plot\n",
    "                plt.show()\n",
    "\n",
    "                # Save the plot to file\n",
    "                plt.savefig(f\"{valley_id}_{feature.replace(' ', '_')}_forecast.png\")\n",
    "                plt.close()\n",
    "\n",
    "                logging.info(f\"Plot saved for {valley_id} - {feature}\")\n",
    "\n",
    "    def run_pipeline(self) -> Dict[str, TimeSeries]:\n",
    "        \"\"\"\n",
    "        Main execution flow for the forecasting pipeline.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, TimeSeries]: Dictionary of forecast time series.\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        series_dict = self._load_data()\n",
    "        self.full_history = series_dict\n",
    "\n",
    "        # Preprocess data\n",
    "        train_dict, val_dict = self._preprocess_data(series_dict)\n",
    "\n",
    "        # Train model\n",
    "        self._train_model(train_dict, val_dict)\n",
    "\n",
    "        # Calculate forecast horizon\n",
    "        sample_ts = list(series_dict.values())[0]\n",
    "        forecast_end_year = self.config[\"target_year\"]\n",
    "        current_end_year = sample_ts.time_index[-1].year\n",
    "        years_to_forecast = forecast_end_year - current_end_year\n",
    "\n",
    "        # Convert years to number of time steps based on data frequency\n",
    "        steps_per_year = 12  # Assuming monthly data\n",
    "        if self.config.get(\"frequency\") == \"D\":\n",
    "            steps_per_year = 365\n",
    "        horizon = years_to_forecast * steps_per_year\n",
    "\n",
    "        print(f\"Forecasting {years_to_forecast} years ahead ({horizon} time steps)\")\n",
    "\n",
    "        # Generate forecasts\n",
    "        forecasts = self._forecast(train_dict, horizon)\n",
    "\n",
    "        # Plot results\n",
    "        self._plot_forecasts(self.full_history, forecasts, val_dict)\n",
    "\n",
    "        return forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create and run the forecaster\n",
    "forecaster = WeatherForecaster(CONFIG)\n",
    "results = forecaster.run_pipeline()\n",
    "print(f\"Forecasting complete. Results saved as PNG files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Compare different models\n",
    "def compare_models(config, target_columns=None):\n",
    "    \"\"\"Compare performance of different models on the dataset.\"\"\"\n",
    "    if target_columns is None:\n",
    "        target_columns = config[\"target_columns\"][:1]  # Just use first target for comparison\n",
    "\n",
    "    model_types = [\"NBEATSModel\", \"BlockRNNModel\", \"TCNModel\", \"TFTModel\"]\n",
    "    results = {}\n",
    "\n",
    "    for model_type in model_types:\n",
    "        print(f\"\\nTraining {model_type}...\")\n",
    "\n",
    "        # Update config with current model\n",
    "        test_config = config.copy()\n",
    "        test_config[\"model_type\"] = model_type\n",
    "        test_config[\"target_columns\"] = target_columns\n",
    "        test_config[\"n_epochs\"] = 20  # Reduced for comparison\n",
    "\n",
    "        try:\n",
    "            forecaster = WeatherForecaster(test_config)\n",
    "            # Load data\n",
    "            series_dict = forecaster._load_data()\n",
    "            # Preprocess data\n",
    "            train_dict, val_dict = forecaster._preprocess_data(series_dict)\n",
    "            # Train model\n",
    "            forecaster._train_model(train_dict, val_dict)\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            val_metrics = {}\n",
    "            for valley_id in val_dict.keys():\n",
    "                val_true = forecaster.scalers[valley_id].inverse_transform(val_dict[valley_id])\n",
    "\n",
    "                # Generate predictions for validation period\n",
    "                val_pred = forecaster.model.predict(\n",
    "                    n=len(val_true),\n",
    "                    series=train_dict[valley_id],\n",
    "                    past_covariates=forecaster.covariates[valley_id] if forecaster.covariates else None\n",
    "                )\n",
    "                val_pred = forecaster.scalers[valley_id].inverse_transform(val_pred)\n",
    "\n",
    "                # Calculate metrics\n",
    "                mae_val = mae(val_true, val_pred)\n",
    "                mape_val = mape(val_true, val_pred)\n",
    "                val_metrics[valley_id] = {\"MAE\": mae_val, \"MAPE\": mape_val}\n",
    "\n",
    "            results[model_type] = val_metrics\n",
    "            print(f\"{model_type} validation metrics: {val_metrics}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {model_type}: {str(e)}\")\n",
    "            results[model_type] = {\"error\": str(e)}\n",
    "\n",
    "    # Display comparison table\n",
    "    comparison_df = pd.DataFrame({\n",
    "        model: {f\"{valley_id}_MAE\": metrics.get(valley_id, {}).get(\"MAE\", None)\n",
    "                for valley_id in config[\"valley_ids\"]}\n",
    "        for model, metrics in results.items()\n",
    "    })\n",
    "\n",
    "    return comparison_df\n",
    "\n",
    "# Uncomment to run model comparison\n",
    "# model_comparison = compare_models(CONFIG)\n",
    "# model_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def multistation_approach_example():\n",
    "    \"\"\"\n",
    "    Example of different approaches to handle multiple weather stations and valleys.\n",
    "    Showing code structure without actual implementation.\n",
    "    \"\"\"\n",
    "    print(\"Three main approaches for handling multiple valleys/stations:\")\n",
    "\n",
    "    # Approach 1: Item ID approach (like in the main code)\n",
    "    print(\"\\n1. Item ID Approach:\")\n",
    "    print(\"- Each valley/station is treated as a separate time series\")\n",
    "    print(\"- Advantage: Simple, allows different scaling per station\")\n",
    "    print(\"- Implementation: Already shown in main code\")\n",
    "\n",
    "    # Approach 2: Multivariate approach\n",
    "    print(\"\\n2. Multivariate Approach:\")\n",
    "    print(\"- All features from all stations in one multivariate time series\")\n",
    "    print(\"- Advantage: Model learns correlations between stations\")\n",
    "\n",
    "    print(\"\"\"\n",
    "    # Example implementation (pseudocode):\n",
    "    def load_multivariate_data():\n",
    "        # Load data from all stations\n",
    "        all_stations_df = []\n",
    "        for station in stations:\n",
    "            df = pd.read_csv(f\"{station}_data.csv\")\n",
    "            # Rename columns to include station\n",
    "            for col in feature_columns:\n",
    "                df.rename(columns={col: f\"{col}_{station}\"}, inplace=True)\n",
    "            all_stations_df.append(df)\n",
    "\n",
    "        # Merge on timestamp\n",
    "        merged_df = pd.merge(all_stations_df, on=\"timestamp\")\n",
    "\n",
    "        # Convert to Darts TimeSeries\n",
    "        ts = TimeSeries.from_dataframe(\n",
    "            merged_df,\n",
    "            time_col=\"timestamp\",\n",
    "            value_cols=[f\"{col}_{station}\" for col in feature_columns for station in stations]\n",
    "        )\n",
    "        return ts\n",
    "    \"\"\")\n",
    "\n",
    "    # Approach 3: One-hot encoding approach\n",
    "    print(\"\\n3. One-hot Encoding Approach:\")\n",
    "    print(\"- Add station/valley identifiers as one-hot encoded features\")\n",
    "    print(\"- Advantage: Allows model to learn location-specific patterns\")\n",
    "\n",
    "    print(\"\"\"\n",
    "    # Example implementation (pseudocode):\n",
    "    def generate_station_covariates(ts, station_id):\n",
    "        # Create one-hot encoding for stations\n",
    "        station_ids = [\"station1\", \"station2\", \"station3\", \"station4\"]\n",
    "        one_hot = [1 if station_id == sid else 0 for sid in station_ids]\n",
    "\n",
    "        # Create covariates TimeSeries with same time index\n",
    "        covariates_data = np.tile(one_hot, (len(ts), 1))\n",
    "        covariates = TimeSeries.from_values(covariates_data, index=ts.time_index)\n",
    "\n",
    "        return covariates\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"\\nRecommendation: Use multivariate approach for stations within the same valley,\")\n",
    "    print(\"and item_id approach for different valleys.\")\n",
    "\n",
    "# multistation_approach_example()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
